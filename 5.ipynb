{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4b42e98",
   "metadata": {},
   "source": [
    "!pip install -U spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af61062",
   "metadata": {},
   "source": [
    "!pip install Arabic-Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c0e9e7",
   "metadata": {},
   "source": [
    "conda install -c conda-forge spacy-model-en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fd44e2",
   "metadata": {},
   "source": [
    "!pip install nltk --quite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c0fcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import argparse\n",
    "import spacy\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16d41458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mjeed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc862b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arabicstopwords.arabicstopwords as stp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b75fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66dc97c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"Arabic Poem Comprehensive Dataset (APCD).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0da7ca53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>era</th>\n",
       "      <th>poet</th>\n",
       "      <th>poetical_works</th>\n",
       "      <th>rhyme</th>\n",
       "      <th>measure</th>\n",
       "      <th>r_hemistich</th>\n",
       "      <th>l_hemistich</th>\n",
       "      <th>line_of_poetry</th>\n",
       "      <th>line_of_poetry_split</th>\n",
       "      <th>line_of_poetry_split_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بن قميئة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>وأن تجمعا شملي وتنتظرا غدا</td>\n",
       "      <td>خليلي لا تستعجلا أن تزودا</td>\n",
       "      <td>خليلي تستعجلا ان تزودا وان تجمعا شملي وتنتظرا</td>\n",
       "      <td>[خليلي, تستعجلا, ان, تزودا, وان, تجمعا, شملي, ...</td>\n",
       "      <td>[خليلي, تستعجلا, ان, تزودا, وان, تجمعا, شملي, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بن قميئة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>ولا سرعتي يوما بسابقة الردى</td>\n",
       "      <td>فما لبث يوما بسابق مغنم</td>\n",
       "      <td>فما لبث يوما بسابق مغنم سرعتي يوما بسابقه الردي</td>\n",
       "      <td>[فما, لبث, يوما, بسابق, مغنم, سرعتي, يوما, بسا...</td>\n",
       "      <td>[فما, لبث, يوما, بسابق, مغنم, سرعتي, يوما, بسا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بن قميئة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>وتستوجبا منا علي وتحمدا</td>\n",
       "      <td>وإن تنظراني اليوم أقض لبانة</td>\n",
       "      <td>وان تنظراني اليوم اقض لبانه وتستوجبا منا علي و...</td>\n",
       "      <td>[وان, تنظراني, اليوم, اقض, لبانه, وتستوجبا, من...</td>\n",
       "      <td>[وان, تنظراني, اليوم, اقض, لبانه, وتستوجبا, من...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بن قميئة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>تؤامرني سرا لأصرم مرثدا</td>\n",
       "      <td>لعمرك ما نفس بجد رشيدة</td>\n",
       "      <td>لعمرك بجد رشيده تءامرني لاصرم مرثدا</td>\n",
       "      <td>[لعمرك, بجد, رشيده, تءامرني, لاصرم, مرثدا]</td>\n",
       "      <td>[لعمرك, بجد, رشيده, تءامرني, لاصرم, مرثدا]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بن قميئة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>وأفرع في لومي مرارا وأصعدا</td>\n",
       "      <td>وإن ظهرت منه قوارص جمة</td>\n",
       "      <td>وان ظهرت قوارص جمه وافرع لومي مرارا واصعدا</td>\n",
       "      <td>[وان, ظهرت, قوارص, جمه, وافرع, لومي, مرارا, وا...</td>\n",
       "      <td>[وان, ظهرت, قوارص, جمه, وافرع, لومي, مرارا, وا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بن قميئة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>سوى قول باغ كادني فتجهدا</td>\n",
       "      <td>على غير ذنب أن أكون جنيته</td>\n",
       "      <td>علي ذنب ان اكون جنيته سوي قول باغ كادني فتجهدا</td>\n",
       "      <td>[علي, ذنب, ان, اكون, جنيته, سوي, قول, باغ, كاد...</td>\n",
       "      <td>[علي, ذنب, ان, اكون, جنيته, سوي, قول, باغ, كاد...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بن قميئة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>إذا ما المنادي في المقامة نددا</td>\n",
       "      <td>لعمري لنعم المرء تدعو بحبله</td>\n",
       "      <td>لعمري لنعم المرء تدعو بحبله اذا المنادي المقام...</td>\n",
       "      <td>[لعمري, لنعم, المرء, تدعو, بحبله, اذا, المنادي...</td>\n",
       "      <td>[لعمري, لنعم, المرء, تدعو, بحبله, اذا, المنادي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بن قميئة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>ولا مؤيس منها إذا هو أوقدا</td>\n",
       "      <td>عظيم رماد القدر لا متعبس</td>\n",
       "      <td>عظيم رماد القدر متعبس مءيس اذا اوقدا</td>\n",
       "      <td>[عظيم, رماد, القدر, متعبس, مءيس, اذا, اوقدا]</td>\n",
       "      <td>[عظيم, رماد, القدر, متعبس, مءيس, اذا, اوقدا]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بن قميئة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>من الريح لم تترك لذي المال مرفدا</td>\n",
       "      <td>وإن صرحت كحل وهبت عرية</td>\n",
       "      <td>وان صرحت كحل وهبت عريه الريح تترك لذي المال مرفدا</td>\n",
       "      <td>[وان, صرحت, كحل, وهبت, عريه, الريح, تترك, لذي,...</td>\n",
       "      <td>[وان, صرحت, كحل, وهبت, عريه, الريح, تترك, لذي,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بن قميئة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>إذا ضن ذو القربى عليهم وأخمدا</td>\n",
       "      <td>صبرت على وطء الموالي وحطمهم</td>\n",
       "      <td>صبرت علي وطء الموالي وحطمهم اذا ضن القربي عليه...</td>\n",
       "      <td>[صبرت, علي, وطء, الموالي, وحطمهم, اذا, ضن, الق...</td>\n",
       "      <td>[صبرت, علي, وطء, الموالي, وحطمهم, اذا, ضن, الق...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           era           poet   poetical_works rhyme measure  \\\n",
       "0  قبل الإسلام  عمرو بن قميئة  الديوان الرئيسي     د  الطويل   \n",
       "1  قبل الإسلام  عمرو بن قميئة  الديوان الرئيسي     د  الطويل   \n",
       "2  قبل الإسلام  عمرو بن قميئة  الديوان الرئيسي     د  الطويل   \n",
       "3  قبل الإسلام  عمرو بن قميئة  الديوان الرئيسي     د  الطويل   \n",
       "4  قبل الإسلام  عمرو بن قميئة  الديوان الرئيسي     د  الطويل   \n",
       "5  قبل الإسلام  عمرو بن قميئة  الديوان الرئيسي     د  الطويل   \n",
       "6  قبل الإسلام  عمرو بن قميئة  الديوان الرئيسي     د  الطويل   \n",
       "7  قبل الإسلام  عمرو بن قميئة  الديوان الرئيسي     د  الطويل   \n",
       "8  قبل الإسلام  عمرو بن قميئة  الديوان الرئيسي     د  الطويل   \n",
       "9  قبل الإسلام  عمرو بن قميئة  الديوان الرئيسي     د  الطويل   \n",
       "\n",
       "                        r_hemistich                  l_hemistich  \\\n",
       "0        وأن تجمعا شملي وتنتظرا غدا    خليلي لا تستعجلا أن تزودا   \n",
       "1       ولا سرعتي يوما بسابقة الردى      فما لبث يوما بسابق مغنم   \n",
       "2           وتستوجبا منا علي وتحمدا  وإن تنظراني اليوم أقض لبانة   \n",
       "3           تؤامرني سرا لأصرم مرثدا       لعمرك ما نفس بجد رشيدة   \n",
       "4        وأفرع في لومي مرارا وأصعدا       وإن ظهرت منه قوارص جمة   \n",
       "5          سوى قول باغ كادني فتجهدا    على غير ذنب أن أكون جنيته   \n",
       "6    إذا ما المنادي في المقامة نددا  لعمري لنعم المرء تدعو بحبله   \n",
       "7        ولا مؤيس منها إذا هو أوقدا     عظيم رماد القدر لا متعبس   \n",
       "8  من الريح لم تترك لذي المال مرفدا       وإن صرحت كحل وهبت عرية   \n",
       "9     إذا ضن ذو القربى عليهم وأخمدا  صبرت على وطء الموالي وحطمهم   \n",
       "\n",
       "                                      line_of_poetry  \\\n",
       "0      خليلي تستعجلا ان تزودا وان تجمعا شملي وتنتظرا   \n",
       "1    فما لبث يوما بسابق مغنم سرعتي يوما بسابقه الردي   \n",
       "2  وان تنظراني اليوم اقض لبانه وتستوجبا منا علي و...   \n",
       "3                لعمرك بجد رشيده تءامرني لاصرم مرثدا   \n",
       "4         وان ظهرت قوارص جمه وافرع لومي مرارا واصعدا   \n",
       "5     علي ذنب ان اكون جنيته سوي قول باغ كادني فتجهدا   \n",
       "6  لعمري لنعم المرء تدعو بحبله اذا المنادي المقام...   \n",
       "7               عظيم رماد القدر متعبس مءيس اذا اوقدا   \n",
       "8  وان صرحت كحل وهبت عريه الريح تترك لذي المال مرفدا   \n",
       "9  صبرت علي وطء الموالي وحطمهم اذا ضن القربي عليه...   \n",
       "\n",
       "                                line_of_poetry_split  \\\n",
       "0  [خليلي, تستعجلا, ان, تزودا, وان, تجمعا, شملي, ...   \n",
       "1  [فما, لبث, يوما, بسابق, مغنم, سرعتي, يوما, بسا...   \n",
       "2  [وان, تنظراني, اليوم, اقض, لبانه, وتستوجبا, من...   \n",
       "3         [لعمرك, بجد, رشيده, تءامرني, لاصرم, مرثدا]   \n",
       "4  [وان, ظهرت, قوارص, جمه, وافرع, لومي, مرارا, وا...   \n",
       "5  [علي, ذنب, ان, اكون, جنيته, سوي, قول, باغ, كاد...   \n",
       "6  [لعمري, لنعم, المرء, تدعو, بحبله, اذا, المنادي...   \n",
       "7       [عظيم, رماد, القدر, متعبس, مءيس, اذا, اوقدا]   \n",
       "8  [وان, صرحت, كحل, وهبت, عريه, الريح, تترك, لذي,...   \n",
       "9  [صبرت, علي, وطء, الموالي, وحطمهم, اذا, ضن, الق...   \n",
       "\n",
       "                           line_of_poetry_split_stop  \n",
       "0  [خليلي, تستعجلا, ان, تزودا, وان, تجمعا, شملي, ...  \n",
       "1  [فما, لبث, يوما, بسابق, مغنم, سرعتي, يوما, بسا...  \n",
       "2  [وان, تنظراني, اليوم, اقض, لبانه, وتستوجبا, من...  \n",
       "3         [لعمرك, بجد, رشيده, تءامرني, لاصرم, مرثدا]  \n",
       "4  [وان, ظهرت, قوارص, جمه, وافرع, لومي, مرارا, وا...  \n",
       "5  [علي, ذنب, ان, اكون, جنيته, سوي, قول, باغ, كاد...  \n",
       "6  [لعمري, لنعم, المرء, تدعو, بحبله, اذا, المنادي...  \n",
       "7       [عظيم, رماد, القدر, متعبس, مءيس, اذا, اوقدا]  \n",
       "8  [وان, صرحت, كحل, وهبت, عريه, الريح, تترك, لذي,...  \n",
       "9  [صبرت, علي, وطء, الموالي, وحطمهم, اذا, ضن, الق...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62ac962",
   "metadata": {},
   "source": [
    "df.columns =['era', 'bard', 'boetical_works', 'rhyme','measure', 'l_hemistich', 'r_hemistich', 'line_of_poetry'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a91b4fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"العصر\":\"era\"},inplace=True)\n",
    "df.rename(columns={\"الشاعر\":\"poet\"},inplace=True)\n",
    "df.rename(columns={\"الديوان\":\"poetical_works\"},inplace=True)\n",
    "df.rename(columns={\"القافية\":\"rhyme\"},inplace=True)\n",
    "df.rename(columns={\"البحر\":\"measure\"},inplace=True)\n",
    "df.rename(columns={\"البيت\":\"line_of_poetry\"},inplace=True)\n",
    "df.rename(columns={\"الشطر الايمن\":\"l_hemistich\"},inplace=True)\n",
    "df.rename(columns={\"الشطر الايسر\":\"r_hemistich\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9da2c0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mjeed\\anaconda3\\lib\\site-packages\\spacy\\util.py:833: UserWarning: [W095] Model 'en_core_web_sm' (3.1.0) was trained with spaCy v3.1 and may not be 100% compatible with the current version (3.2.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'above', 'about', 'now', 'besides', 'could', 'here', 'quite', 'himself', 'before', 'else', 'cannot', 'due', 'whose', 'whence', 'neither', 'towards', 'been', 'thereafter', 'seeming', '’d', 'move', 'few', 'my', 'two', 'used', 'whenever', 'throughout', 'has', 'empty', 'was', 'much', 'name', 'what', 'yet', 'ca', 'myself', 'on', 'when', 'whereupon', '‘s', 'top', 'however', 'whither', 'n’t', 'how', 'anyway', 'nowhere', 'very', 'so', 'though', 'either', 'rather', '‘ve', \"'d\", 'him', 'get', 'if', '‘re', 'eleven', 'toward', 'put', 'made', 'is', 'eight', 'unless', 'whatever', 'those', 'almost', 'always', 'why', 'nothing', 'us', 'amongst', 'four', 'from', 'nobody', 'some', 'ours', 'call', 'every', 'last', 'afterwards', 'any', 'mine', 'first', 'under', 'see', 'for', 'hundred', 'of', 'hereby', 'next', \"'re\", 'where', 'had', 're', 'ever', 'this', 'between', 'namely', 'whom', 'across', 'nor', 'ten', 'thereby', 'elsewhere', 'somewhere', 'your', 'indeed', 'no', 'does', 'sometime', 'nevertheless', 'as', 'whereas', 'former', 'than', 'down', 'others', 'thru', 'everyone', 'something', 'once', 'well', 'that', 'make', 'against', 'anyhow', 'doing', 'both', 'everywhere', 'own', 'over', 'hereupon', 'me', 'might', 'nine', 'therein', 'just', 'up', 'by', 'even', 'although', 'perhaps', 'you', 'i', 'one', 'around', 'out', 'hereafter', 'again', 'ourselves', 'twelve', 'front', 'their', 'there', 'itself', 'into', 'which', '’re', 'done', 'should', 'several', 'it', '’ll', 'five', 'everything', 'anything', 'its', 'yours', 'other', 'each', 'onto', 'becomes', 'thence', 'will', 'seemed', 'therefore', 'fifteen', 'he', 'such', 'whereby', 'together', '’ve', 'became', 'third', 'fifty', 'side', 'latter', 'three', 'go', 'these', 'were', 'still', 'moreover', 'then', 'or', 'a', \"'s\", 'them', 'meanwhile', 'noone', 'full', 'we', 'must', 'an', 'except', 'becoming', 'behind', 'until', 'least', 'really', 'never', 'may', 'whether', 'say', 'beyond', 'are', 'while', 'bottom', 'beforehand', 'at', 'more', 'herein', 'yourselves', 'thus', 'per', 'wherever', 'wherein', 'too', 'formerly', 'am', 'become', 'already', '‘m', 'and', 'show', 'forty', 'anyone', 'who', 'upon', 'please', 'be', 'take', 'off', 'would', 'whole', 'via', 'seem', 'she', '‘ll', 'after', '’m', 'many', 'sometimes', 'to', 'only', 'our', 'because', 'most', 'being', 'seems', 'alone', \"'ll\", 'further', 'back', 'whereafter', 'within', 'in', 'mostly', 'latterly', 'but', 'the', 'did', 'through', 'also', 'amount', 'have', 'whoever', '’s', 'regarding', 'her', 'with', 'they', 'themselves', 'his', \"'m\", 'twenty', 'serious', 'keep', 'somehow', 'none', 'without', 'among', 'yourself', 'herself', 'various', \"n't\", 'same', 'using', 'give', 'below', 'another', 'not', \"'ve\", 'can', 'beside', 'sixty', 'someone', 'anywhere', 'along', 'since', 'do', 'less', 'enough', 'part', 'during', 'six', 'hence', 'otherwise', 'thereupon', 'n‘t', 'hers', 'all', '‘d', 'often'}\n"
     ]
    }
   ],
   "source": [
    "en = spacy.load('en_core_web_sm')\n",
    "sw_spacy = en.Defaults.stop_words\n",
    "print(sw_spacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c22d3c",
   "metadata": {},
   "source": [
    "# تشكــــــــــــــــــــــيل"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78598b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"l_hemistich\"] = df[\"l_hemistich\"].astype(str)\n",
    "df[\"r_hemistich\"] = df[\"r_hemistich\"].astype(str) \n",
    "df[\"poetical_works\"] = df[\"poetical_works\"].astype(str)\n",
    "df[\"poet\"] = df[\"poet\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24981e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tashkeel(text):\n",
    " #  Remove tashkeel\n",
    "    text = text.replace(\"\\u064B\", \"\")  # ARABIC FATHATAN\n",
    "    text = text.replace(\"\\u064C\", \"\")  # ARABIC DAMMATAN\n",
    "    text = text.replace(\"\\u064D\", \"\")  # ARABIC KASRATAN\n",
    "    text = text.replace(\"\\u064E\", \"\")  # ARABIC FATHA\n",
    "    text = text.replace(\"\\u064F\", \"\")  # ARABIC DAMMA\n",
    "    text = text.replace(\"\\u0650\", \"\")  # ARABIC KASRA\n",
    "    text = text.replace(\"\\u0651\", \"\")  # ARABIC SHADDA\n",
    "    text = text.replace(\"\\u0652\", \"\")  # ARABIC SUKUN\n",
    "    text = text.replace(\"\\u0653\", \"\")  # ARABIC MADDAH ABOVE\n",
    "    text = text.replace(\"\\u0654\", \"\")  # ARABIC HAMZA ABOVE\n",
    "    text = text.replace(\"\\u0655\", \"\")  # ARABIC HAMZA BELOW\n",
    "    text = text.replace(\"\\u0656\", \"\")  # ARABIC SUBSCRIPT ALEF\n",
    "    text = text.replace(\"\\u0657\", \"\")  # ARABIC INVERTED DAMMA\n",
    "    text = text.replace(\"\\u0658\", \"\")  # ARABIC MARK NOON GHUNNA\n",
    "    text = text.replace(\"\\u0659\", \"\")  # ARABIC ZWARAKAY\n",
    "    text = text.replace(\"\\u065A\", \"\")  # ARABIC VOWEL SIGN SMALL V ABOVE\n",
    "    text = text.replace(\"\\u065B\", \"\")  # ARABIC VOWEL SIGN INVERTED SMALL V ABOVE\n",
    "    text = text.replace(\"\\u065C\", \"\")  # ARABIC VOWEL SIGN DOT BELOW\n",
    "    text = text.replace(\"\\u065D\", \"\")  # ARABIC REVERSED DAMMA\n",
    "    text = text.replace(\"\\u065E\", \"\")  # ARABIC FATHA WITH TWO DOTS\n",
    "    text = text.replace(\"\\u065F\", \"\")  # ARABIC WAVY HAMZA BELOW\n",
    "    text = text.replace(\"\\u0670\", \"\")  # ARABIC LETTER SUPERSCRIPT ALEF\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2596e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['r_hemistich'] = df['r_hemistich'].apply(remove_tashkeel)\n",
    "df['l_hemistich'] = df['l_hemistich'].apply(remove_tashkeel)\n",
    "df['line_of_poetry'] = df['line_of_poetry'].apply(remove_tashkeel)\n",
    "df['era'] = df['era'].apply(remove_tashkeel)\n",
    "df['poet'] = df['poet'].apply(remove_tashkeel)\n",
    "df['poetical_works'] = df['poetical_works'].apply(remove_tashkeel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8562e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>era</th>\n",
       "      <th>poet</th>\n",
       "      <th>poetical_works</th>\n",
       "      <th>rhyme</th>\n",
       "      <th>measure</th>\n",
       "      <th>r_hemistich</th>\n",
       "      <th>l_hemistich</th>\n",
       "      <th>line_of_poetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بن قميئة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>وأن تجمعا شملي وتنتظرا غدا</td>\n",
       "      <td>خليلي لا تستعجلا أن تزودا</td>\n",
       "      <td>خليلي لا تستعجلا أن تزودا    وأن تجمعا شملي وت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بن قميئة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>ولا سرعتي يوما بسابقة الردى</td>\n",
       "      <td>فما لبث يوما بسابق مغنم</td>\n",
       "      <td>فما لبث يوما بسابق مغنم    ولا سرعتي يوما بساب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بن قميئة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>وتستوجبا منا علي وتحمدا</td>\n",
       "      <td>وإن تنظراني اليوم أقض لبانة</td>\n",
       "      <td>وإن تنظراني اليوم أقض لبانة    وتستوجبا منا عل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بن قميئة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>تؤامرني سرا لأصرم مرثدا</td>\n",
       "      <td>لعمرك ما نفس بجد رشيدة</td>\n",
       "      <td>لعمرك ما نفس بجد رشيدة    تؤامرني سرا لأصرم مرثدا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بن قميئة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>وأفرع في لومي مرارا وأصعدا</td>\n",
       "      <td>وإن ظهرت منه قوارص جمة</td>\n",
       "      <td>وإن ظهرت منه قوارص جمة    وأفرع في لومي مرارا ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831765</th>\n",
       "      <td>الحديث</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>ن</td>\n",
       "      <td>الخفيف</td>\n",
       "      <td>وأحلى قصيدة تتغنى</td>\n",
       "      <td>هي أغلى ما أنشأ الله في الدنيا</td>\n",
       "      <td>هي أغلى ما أنشأ الله في الدنيا    وأحلى قصيدة ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831766</th>\n",
       "      <td>الحديث</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>ن</td>\n",
       "      <td>الخفيف</td>\n",
       "      <td>كحلم يغشى الجفون الوسنى</td>\n",
       "      <td>هي أغرودة الأغاريد تنساب</td>\n",
       "      <td>هي أغرودة الأغاريد تنساب    كحلم يغشى الجفون ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831767</th>\n",
       "      <td>الحديث</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>ن</td>\n",
       "      <td>الخفيف</td>\n",
       "      <td>يتداعى وجدا ويخفق حسنا</td>\n",
       "      <td>هي شلال بهجة وبهاء</td>\n",
       "      <td>هي شلال بهجة وبهاء    يتداعى وجدا ويخفق حسنا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831768</th>\n",
       "      <td>الحديث</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>ن</td>\n",
       "      <td>الخفيف</td>\n",
       "      <td>يدك الحدود سجنا فسجنا</td>\n",
       "      <td>هي حلم الهوى ومنطلقي الباقي</td>\n",
       "      <td>هي حلم الهوى ومنطلقي الباقي    يدك الحدود سجنا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831769</th>\n",
       "      <td>الحديث</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>ن</td>\n",
       "      <td>الخفيف</td>\n",
       "      <td>آه لو أدرك الغرام لجنا</td>\n",
       "      <td>هي حبي العاتي وكل غرامي</td>\n",
       "      <td>هي حبي العاتي وكل غرامي    آه لو أدرك الغرام لجنا</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1831770 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 era           poet   poetical_works rhyme measure  \\\n",
       "0        قبل الإسلام  عمرو بن قميئة  الديوان الرئيسي     د  الطويل   \n",
       "1        قبل الإسلام  عمرو بن قميئة  الديوان الرئيسي     د  الطويل   \n",
       "2        قبل الإسلام  عمرو بن قميئة  الديوان الرئيسي     د  الطويل   \n",
       "3        قبل الإسلام  عمرو بن قميئة  الديوان الرئيسي     د  الطويل   \n",
       "4        قبل الإسلام  عمرو بن قميئة  الديوان الرئيسي     د  الطويل   \n",
       "...              ...            ...              ...   ...     ...   \n",
       "1831765       الحديث      شهاب غانم        شهاب غانم     ن  الخفيف   \n",
       "1831766       الحديث      شهاب غانم        شهاب غانم     ن  الخفيف   \n",
       "1831767       الحديث      شهاب غانم        شهاب غانم     ن  الخفيف   \n",
       "1831768       الحديث      شهاب غانم        شهاب غانم     ن  الخفيف   \n",
       "1831769       الحديث      شهاب غانم        شهاب غانم     ن  الخفيف   \n",
       "\n",
       "                         r_hemistich                     l_hemistich  \\\n",
       "0         وأن تجمعا شملي وتنتظرا غدا       خليلي لا تستعجلا أن تزودا   \n",
       "1        ولا سرعتي يوما بسابقة الردى         فما لبث يوما بسابق مغنم   \n",
       "2            وتستوجبا منا علي وتحمدا     وإن تنظراني اليوم أقض لبانة   \n",
       "3            تؤامرني سرا لأصرم مرثدا          لعمرك ما نفس بجد رشيدة   \n",
       "4         وأفرع في لومي مرارا وأصعدا          وإن ظهرت منه قوارص جمة   \n",
       "...                              ...                             ...   \n",
       "1831765            وأحلى قصيدة تتغنى  هي أغلى ما أنشأ الله في الدنيا   \n",
       "1831766      كحلم يغشى الجفون الوسنى        هي أغرودة الأغاريد تنساب   \n",
       "1831767       يتداعى وجدا ويخفق حسنا              هي شلال بهجة وبهاء   \n",
       "1831768        يدك الحدود سجنا فسجنا     هي حلم الهوى ومنطلقي الباقي   \n",
       "1831769       آه لو أدرك الغرام لجنا         هي حبي العاتي وكل غرامي   \n",
       "\n",
       "                                            line_of_poetry  \n",
       "0        خليلي لا تستعجلا أن تزودا    وأن تجمعا شملي وت...  \n",
       "1        فما لبث يوما بسابق مغنم    ولا سرعتي يوما بساب...  \n",
       "2        وإن تنظراني اليوم أقض لبانة    وتستوجبا منا عل...  \n",
       "3        لعمرك ما نفس بجد رشيدة    تؤامرني سرا لأصرم مرثدا  \n",
       "4        وإن ظهرت منه قوارص جمة    وأفرع في لومي مرارا ...  \n",
       "...                                                    ...  \n",
       "1831765  هي أغلى ما أنشأ الله في الدنيا    وأحلى قصيدة ...  \n",
       "1831766  هي أغرودة الأغاريد تنساب    كحلم يغشى الجفون ا...  \n",
       "1831767       هي شلال بهجة وبهاء    يتداعى وجدا ويخفق حسنا  \n",
       "1831768  هي حلم الهوى ومنطلقي الباقي    يدك الحدود سجنا...  \n",
       "1831769  هي حبي العاتي وكل غرامي    آه لو أدرك الغرام لجنا  \n",
       "\n",
       "[1831770 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d398597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mjeed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "820098bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mjeed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words()\n",
    "def preprocess(text):\n",
    "    \n",
    "    '''\n",
    "    text is an arabic string input\n",
    "    \n",
    "    the preprocessed text is returned\n",
    "    '''\n",
    "    \n",
    "    #remove punctuations\n",
    "    translator = str.maketrans('', '', punctuations)\n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    #remove longation\n",
    "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"ؤ\", \"ء\", text)\n",
    "    text = re.sub(\"ئ\", \"ء\", text)\n",
    "    text = re.sub(\"ة\", \"ه\", text)\n",
    "    text = re.sub(\"گ\", \"ك\", text)\n",
    "\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e7d01e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['line_of_poetry'] = df['line_of_poetry'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c53d82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ازالة على باقي الكولم تاخذ وقت في الرن \n",
    "#df['r_hemistich'] = df['r_hemistich'].apply(preprocess)\n",
    "#df['l_hemistich'] = df['l_hemistich'].apply(preprocess)\n",
    "#df['era'] = df['era'].apply(preprocess)\n",
    "#df['poet'] = df['poet'].apply(preprocess)\n",
    "#df['poetical_works'] = df['poetical_works'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3764b5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>era</th>\n",
       "      <th>poet</th>\n",
       "      <th>poetical_works</th>\n",
       "      <th>rhyme</th>\n",
       "      <th>measure</th>\n",
       "      <th>r_hemistich</th>\n",
       "      <th>l_hemistich</th>\n",
       "      <th>line_of_poetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بن قميئة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>وأن تجمعا شملي وتنتظرا غدا</td>\n",
       "      <td>خليلي لا تستعجلا أن تزودا</td>\n",
       "      <td>خليلي تستعجلا ان تزودا وان تجمعا شملي وتنتظرا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بن قميئة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>ولا سرعتي يوما بسابقة الردى</td>\n",
       "      <td>فما لبث يوما بسابق مغنم</td>\n",
       "      <td>فما لبث يوما بسابق مغنم سرعتي يوما بسابقه الردي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بن قميئة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>وتستوجبا منا علي وتحمدا</td>\n",
       "      <td>وإن تنظراني اليوم أقض لبانة</td>\n",
       "      <td>وان تنظراني اليوم اقض لبانه وتستوجبا منا علي و...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بن قميئة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>تؤامرني سرا لأصرم مرثدا</td>\n",
       "      <td>لعمرك ما نفس بجد رشيدة</td>\n",
       "      <td>لعمرك بجد رشيده تءامرني لاصرم مرثدا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بن قميئة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>وأفرع في لومي مرارا وأصعدا</td>\n",
       "      <td>وإن ظهرت منه قوارص جمة</td>\n",
       "      <td>وان ظهرت قوارص جمه وافرع لومي مرارا واصعدا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831765</th>\n",
       "      <td>الحديث</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>ن</td>\n",
       "      <td>الخفيف</td>\n",
       "      <td>وأحلى قصيدة تتغنى</td>\n",
       "      <td>هي أغلى ما أنشأ الله في الدنيا</td>\n",
       "      <td>اغلي انشا الله الدنيا واحلي قصيده تتغني</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831766</th>\n",
       "      <td>الحديث</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>ن</td>\n",
       "      <td>الخفيف</td>\n",
       "      <td>كحلم يغشى الجفون الوسنى</td>\n",
       "      <td>هي أغرودة الأغاريد تنساب</td>\n",
       "      <td>اغروده الاغاريد تنساب كحلم يغشي الجفون الوسني</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831767</th>\n",
       "      <td>الحديث</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>ن</td>\n",
       "      <td>الخفيف</td>\n",
       "      <td>يتداعى وجدا ويخفق حسنا</td>\n",
       "      <td>هي شلال بهجة وبهاء</td>\n",
       "      <td>شلال بهجه وبهاء يتداعي وجدا ويخفق حسنا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831768</th>\n",
       "      <td>الحديث</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>ن</td>\n",
       "      <td>الخفيف</td>\n",
       "      <td>يدك الحدود سجنا فسجنا</td>\n",
       "      <td>هي حلم الهوى ومنطلقي الباقي</td>\n",
       "      <td>حلم الهوي ومنطلقي الباقي يدك الحدود سجنا فسجنا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831769</th>\n",
       "      <td>الحديث</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>ن</td>\n",
       "      <td>الخفيف</td>\n",
       "      <td>آه لو أدرك الغرام لجنا</td>\n",
       "      <td>هي حبي العاتي وكل غرامي</td>\n",
       "      <td>حبي العاتي وكل غرامي اه ادرك الغرام لجنا</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1831770 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 era           poet   poetical_works rhyme measure  \\\n",
       "0        قبل الإسلام  عمرو بن قميئة  الديوان الرئيسي     د  الطويل   \n",
       "1        قبل الإسلام  عمرو بن قميئة  الديوان الرئيسي     د  الطويل   \n",
       "2        قبل الإسلام  عمرو بن قميئة  الديوان الرئيسي     د  الطويل   \n",
       "3        قبل الإسلام  عمرو بن قميئة  الديوان الرئيسي     د  الطويل   \n",
       "4        قبل الإسلام  عمرو بن قميئة  الديوان الرئيسي     د  الطويل   \n",
       "...              ...            ...              ...   ...     ...   \n",
       "1831765       الحديث      شهاب غانم        شهاب غانم     ن  الخفيف   \n",
       "1831766       الحديث      شهاب غانم        شهاب غانم     ن  الخفيف   \n",
       "1831767       الحديث      شهاب غانم        شهاب غانم     ن  الخفيف   \n",
       "1831768       الحديث      شهاب غانم        شهاب غانم     ن  الخفيف   \n",
       "1831769       الحديث      شهاب غانم        شهاب غانم     ن  الخفيف   \n",
       "\n",
       "                         r_hemistich                     l_hemistich  \\\n",
       "0         وأن تجمعا شملي وتنتظرا غدا       خليلي لا تستعجلا أن تزودا   \n",
       "1        ولا سرعتي يوما بسابقة الردى         فما لبث يوما بسابق مغنم   \n",
       "2            وتستوجبا منا علي وتحمدا     وإن تنظراني اليوم أقض لبانة   \n",
       "3            تؤامرني سرا لأصرم مرثدا          لعمرك ما نفس بجد رشيدة   \n",
       "4         وأفرع في لومي مرارا وأصعدا          وإن ظهرت منه قوارص جمة   \n",
       "...                              ...                             ...   \n",
       "1831765            وأحلى قصيدة تتغنى  هي أغلى ما أنشأ الله في الدنيا   \n",
       "1831766      كحلم يغشى الجفون الوسنى        هي أغرودة الأغاريد تنساب   \n",
       "1831767       يتداعى وجدا ويخفق حسنا              هي شلال بهجة وبهاء   \n",
       "1831768        يدك الحدود سجنا فسجنا     هي حلم الهوى ومنطلقي الباقي   \n",
       "1831769       آه لو أدرك الغرام لجنا         هي حبي العاتي وكل غرامي   \n",
       "\n",
       "                                            line_of_poetry  \n",
       "0            خليلي تستعجلا ان تزودا وان تجمعا شملي وتنتظرا  \n",
       "1          فما لبث يوما بسابق مغنم سرعتي يوما بسابقه الردي  \n",
       "2        وان تنظراني اليوم اقض لبانه وتستوجبا منا علي و...  \n",
       "3                      لعمرك بجد رشيده تءامرني لاصرم مرثدا  \n",
       "4               وان ظهرت قوارص جمه وافرع لومي مرارا واصعدا  \n",
       "...                                                    ...  \n",
       "1831765            اغلي انشا الله الدنيا واحلي قصيده تتغني  \n",
       "1831766      اغروده الاغاريد تنساب كحلم يغشي الجفون الوسني  \n",
       "1831767             شلال بهجه وبهاء يتداعي وجدا ويخفق حسنا  \n",
       "1831768     حلم الهوي ومنطلقي الباقي يدك الحدود سجنا فسجنا  \n",
       "1831769           حبي العاتي وكل غرامي اه ادرك الغرام لجنا  \n",
       "\n",
       "[1831770 rows x 8 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e43ef4",
   "metadata": {},
   "source": [
    "# تقسيـــــــــــــــــم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0f2cb1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mjeed\\anaconda3\\lib\\site-packages\\spacy\\util.py:833: UserWarning: [W095] Model 'en_core_web_sm' (3.1.0) was trained with spaCy v3.1 and may not be 100% compatible with the current version (3.2.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d9789751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import  word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9da302ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"line_of_poetry_split\"] = df[\"line_of_poetry\"].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "806e348a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [خليلي, تستعجلا, ان, تزودا, وان, تجمعا, شملي, ...\n",
       "1          [فما, لبث, يوما, بسابق, مغنم, سرعتي, يوما, بسا...\n",
       "2          [وان, تنظراني, اليوم, اقض, لبانه, وتستوجبا, من...\n",
       "3                 [لعمرك, بجد, رشيده, تءامرني, لاصرم, مرثدا]\n",
       "4          [وان, ظهرت, قوارص, جمه, وافرع, لومي, مرارا, وا...\n",
       "                                 ...                        \n",
       "1831765      [اغلي, انشا, الله, الدنيا, واحلي, قصيده, تتغني]\n",
       "1831766    [اغروده, الاغاريد, تنساب, كحلم, يغشي, الجفون, ...\n",
       "1831767       [شلال, بهجه, وبهاء, يتداعي, وجدا, ويخفق, حسنا]\n",
       "1831768    [حلم, الهوي, ومنطلقي, الباقي, يدك, الحدود, سجن...\n",
       "1831769    [حبي, العاتي, وكل, غرامي, اه, ادرك, الغرام, لجنا]\n",
       "Name: line_of_poetry_split, Length: 1831770, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"line_of_poetry_split\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8b4147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "130530b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [(خليلي, JJ), (تستعجلا, NNP), (ان, NNP), (تزود...\n",
       "1          [(فما, JJ), (لبث, NNP), (يوما, NNP), (بسابق, N...\n",
       "2          [(وان, JJ), (تنظراني, NNP), (اليوم, NNP), (اقض...\n",
       "3          [(لعمرك, JJ), (بجد, NNP), (رشيده, NNP), (تءامر...\n",
       "4          [(وان, JJ), (ظهرت, NNP), (قوارص, NNP), (جمه, N...\n",
       "                                 ...                        \n",
       "1831765    [(اغلي, JJ), (انشا, NNP), (الله, NNP), (الدنيا...\n",
       "1831766    [(اغروده, JJ), (الاغاريد, NNP), (تنساب, NNP), ...\n",
       "1831767    [(شلال, JJ), (بهجه, NNP), (وبهاء, NNP), (يتداع...\n",
       "1831768    [(حلم, JJ), (الهوي, NNP), (ومنطلقي, NNP), (الب...\n",
       "1831769    [(حبي, JJ), (العاتي, NNP), (وكل, NNP), (غرامي,...\n",
       "Name: line_of_poetry_split, Length: 1831770, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"line_of_poetry_split\"].apply(nltk.pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7ea9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"line_of_poetry_split\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f39c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4846f460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['إذ', 'إذا', 'إذما', 'إذن', 'أف', 'أقل', 'أكثر', 'ألا', 'إلا', 'التي', 'الذي', 'الذين', 'اللاتي', 'اللائي', 'اللتان', 'اللتيا', 'اللتين', 'اللذان', 'اللذين', 'اللواتي', 'إلى', 'إليك', 'إليكم', 'إليكما', 'إليكن', 'أم', 'أما', 'أما', 'إما', 'أن', 'إن', 'إنا', 'أنا', 'أنت', 'أنتم', 'أنتما', 'أنتن', 'إنما', 'إنه', 'أنى', 'أنى', 'آه', 'آها', 'أو', 'أولاء', 'أولئك', 'أوه', 'آي', 'أي', 'أيها', 'إي', 'أين', 'أين', 'أينما', 'إيه', 'بخ', 'بس', 'بعد', 'بعض', 'بك', 'بكم', 'بكم', 'بكما', 'بكن', 'بل', 'بلى', 'بما', 'بماذا', 'بمن', 'بنا', 'به', 'بها', 'بهم', 'بهما', 'بهن', 'بي', 'بين', 'بيد', 'تلك', 'تلكم', 'تلكما', 'ته', 'تي', 'تين', 'تينك', 'ثم', 'ثمة', 'حاشا', 'حبذا', 'حتى', 'حيث', 'حيثما', 'حين', 'خلا', 'دون', 'ذا', 'ذات', 'ذاك', 'ذان', 'ذانك', 'ذلك', 'ذلكم', 'ذلكما', 'ذلكن', 'ذه', 'ذو', 'ذوا', 'ذواتا', 'ذواتي', 'ذي', 'ذين', 'ذينك', 'ريث', 'سوف', 'سوى', 'شتان', 'عدا', 'عسى', 'عل', 'على', 'عليك', 'عليه', 'عما', 'عن', 'عند', 'غير', 'فإذا', 'فإن', 'فلا', 'فمن', 'في', 'فيم', 'فيما', 'فيه', 'فيها', 'قد', 'كأن', 'كأنما', 'كأي', 'كأين', 'كذا', 'كذلك', 'كل', 'كلا', 'كلاهما', 'كلتا', 'كلما', 'كليكما', 'كليهما', 'كم', 'كم', 'كما', 'كي', 'كيت', 'كيف', 'كيفما', 'لا', 'لاسيما', 'لدى', 'لست', 'لستم', 'لستما', 'لستن', 'لسن', 'لسنا', 'لعل', 'لك', 'لكم', 'لكما', 'لكن', 'لكنما', 'لكي', 'لكيلا', 'لم', 'لما', 'لن', 'لنا', 'له', 'لها', 'لهم', 'لهما', 'لهن', 'لو', 'لولا', 'لوما', 'لي', 'لئن', 'ليت', 'ليس', 'ليسا', 'ليست', 'ليستا', 'ليسوا', 'ما', 'ماذا', 'متى', 'مذ', 'مع', 'مما', 'ممن', 'من', 'منه', 'منها', 'منذ', 'مه', 'مهما', 'نحن', 'نحو', 'نعم', 'ها', 'هاتان', 'هاته', 'هاتي', 'هاتين', 'هاك', 'هاهنا', 'هذا', 'هذان', 'هذه', 'هذي', 'هذين', 'هكذا', 'هل', 'هلا', 'هم', 'هما', 'هن', 'هنا', 'هناك', 'هنالك', 'هو', 'هؤلاء', 'هي', 'هيا', 'هيت', 'هيهات', 'والذي', 'والذين', 'وإذ', 'وإذا', 'وإن', 'ولا', 'ولكن', 'ولو', 'وما', 'ومن', 'وهو', 'يا', 'أبٌ', 'أخٌ', 'حمٌ', 'فو', 'أنتِ', 'يناير', 'فبراير', 'مارس', 'أبريل', 'مايو', 'يونيو', 'يوليو', 'أغسطس', 'سبتمبر', 'أكتوبر', 'نوفمبر', 'ديسمبر', 'جانفي', 'فيفري', 'مارس', 'أفريل', 'ماي', 'جوان', 'جويلية', 'أوت', 'كانون', 'شباط', 'آذار', 'نيسان', 'أيار', 'حزيران', 'تموز', 'آب', 'أيلول', 'تشرين', 'دولار', 'دينار', 'ريال', 'درهم', 'ليرة', 'جنيه', 'قرش', 'مليم', 'فلس', 'هللة', 'سنتيم', 'يورو', 'ين', 'يوان', 'شيكل', 'واحد', 'اثنان', 'ثلاثة', 'أربعة', 'خمسة', 'ستة', 'سبعة', 'ثمانية', 'تسعة', 'عشرة', 'أحد', 'اثنا', 'اثني', 'إحدى', 'ثلاث', 'أربع', 'خمس', 'ست', 'سبع', 'ثماني', 'تسع', 'عشر', 'ثمان', 'سبت', 'أحد', 'اثنين', 'ثلاثاء', 'أربعاء', 'خميس', 'جمعة', 'أول', 'ثان', 'ثاني', 'ثالث', 'رابع', 'خامس', 'سادس', 'سابع', 'ثامن', 'تاسع', 'عاشر', 'حادي', 'أ', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ي', 'ء', 'ى', 'آ', 'ؤ', 'ئ', 'أ', 'ة', 'ألف', 'باء', 'تاء', 'ثاء', 'جيم', 'حاء', 'خاء', 'دال', 'ذال', 'راء', 'زاي', 'سين', 'شين', 'صاد', 'ضاد', 'طاء', 'ظاء', 'عين', 'غين', 'فاء', 'قاف', 'كاف', 'لام', 'ميم', 'نون', 'هاء', 'واو', 'ياء', 'همزة', 'ي', 'نا', 'ك', 'كن', 'ه', 'إياه', 'إياها', 'إياهما', 'إياهم', 'إياهن', 'إياك', 'إياكما', 'إياكم', 'إياك', 'إياكن', 'إياي', 'إيانا', 'أولالك', 'تانِ', 'تانِك', 'تِه', 'تِي', 'تَيْنِ', 'ثمّ', 'ثمّة', 'ذانِ', 'ذِه', 'ذِي', 'ذَيْنِ', 'هَؤلاء', 'هَاتانِ', 'هَاتِه', 'هَاتِي', 'هَاتَيْنِ', 'هَذا', 'هَذانِ', 'هَذِه', 'هَذِي', 'هَذَيْنِ', 'الألى', 'الألاء', 'أل', 'أنّى', 'أيّ', 'ّأيّان', 'أنّى', 'أيّ', 'ّأيّان', 'ذيت', 'كأيّ', 'كأيّن', 'بضع', 'فلان', 'وا', 'آمينَ', 'آهِ', 'آهٍ', 'آهاً', 'أُفٍّ', 'أُفٍّ', 'أفٍّ', 'أمامك', 'أمامكَ', 'أوّهْ', 'إلَيْكَ', 'إلَيْكَ', 'إليكَ', 'إليكنّ', 'إيهٍ', 'بخٍ', 'بسّ', 'بَسْ', 'بطآن', 'بَلْهَ', 'حاي', 'حَذارِ', 'حيَّ', 'حيَّ', 'دونك', 'رويدك', 'سرعان', 'شتانَ', 'شَتَّانَ', 'صهْ', 'صهٍ', 'طاق', 'طَق', 'عَدَسْ', 'كِخ', 'مكانَك', 'مكانَك', 'مكانَك', 'مكانكم', 'مكانكما', 'مكانكنّ', 'نَخْ', 'هاكَ', 'هَجْ', 'هلم', 'هيّا', 'هَيْهات', 'وا', 'واهاً', 'وراءَك', 'وُشْكَانَ', 'وَيْ', 'يفعلان', 'تفعلان', 'يفعلون', 'تفعلون', 'تفعلين', 'اتخذ', 'ألفى', 'تخذ', 'ترك', 'تعلَّم', 'جعل', 'حجا', 'حبيب', 'خال', 'حسب', 'خال', 'درى', 'رأى', 'زعم', 'صبر', 'ظنَّ', 'عدَّ', 'علم', 'غادر', 'ذهب', 'وجد', 'ورد', 'وهب', 'أسكن', 'أطعم', 'أعطى', 'رزق', 'زود', 'سقى', 'كسا', 'أخبر', 'أرى', 'أعلم', 'أنبأ', 'حدَث', 'خبَّر', 'نبَّا', 'أفعل به', 'ما أفعله', 'بئس', 'ساء', 'طالما', 'قلما', 'لات', 'لكنَّ', 'ءَ', 'أجل', 'إذاً', 'أمّا', 'إمّا', 'إنَّ', 'أنًّ', 'أى', 'إى', 'أيا', 'ب', 'ثمَّ', 'جلل', 'جير', 'رُبَّ', 'س', 'علًّ', 'ف', 'كأنّ', 'كلَّا', 'كى', 'ل', 'لات', 'لعلَّ', 'لكنَّ', 'لكنَّ', 'م', 'نَّ', 'هلّا', 'وا', 'أل', 'إلّا', 'ت', 'ك', 'لمّا', 'ن', 'ه', 'و', 'ا', 'ي', 'تجاه', 'تلقاء', 'جميع', 'حسب', 'سبحان', 'شبه', 'لعمر', 'مثل', 'معاذ', 'أبو', 'أخو', 'حمو', 'فو', 'مئة', 'مئتان', 'ثلاثمئة', 'أربعمئة', 'خمسمئة', 'ستمئة', 'سبعمئة', 'ثمنمئة', 'تسعمئة', 'مائة', 'ثلاثمائة', 'أربعمائة', 'خمسمائة', 'ستمائة', 'سبعمائة', 'ثمانمئة', 'تسعمائة', 'عشرون', 'ثلاثون', 'اربعون', 'خمسون', 'ستون', 'سبعون', 'ثمانون', 'تسعون', 'عشرين', 'ثلاثين', 'اربعين', 'خمسين', 'ستين', 'سبعين', 'ثمانين', 'تسعين', 'بضع', 'نيف', 'أجمع', 'جميع', 'عامة', 'عين', 'نفس', 'لا سيما', 'أصلا', 'أهلا', 'أيضا', 'بؤسا', 'بعدا', 'بغتة', 'تعسا', 'حقا', 'حمدا', 'خلافا', 'خاصة', 'دواليك', 'سحقا', 'سرا', 'سمعا', 'صبرا', 'صدقا', 'صراحة', 'طرا', 'عجبا', 'عيانا', 'غالبا', 'فرادى', 'فضلا', 'قاطبة', 'كثيرا', 'لبيك', 'معاذ', 'أبدا', 'إزاء', 'أصلا', 'الآن', 'أمد', 'أمس', 'آنفا', 'آناء', 'أنّى', 'أول', 'أيّان', 'تارة', 'ثمّ', 'ثمّة', 'حقا', 'صباح', 'مساء', 'ضحوة', 'عوض', 'غدا', 'غداة', 'قطّ', 'كلّما', 'لدن', 'لمّا', 'مرّة', 'قبل', 'خلف', 'أمام', 'فوق', 'تحت', 'يمين', 'شمال', 'ارتدّ', 'استحال', 'أصبح', 'أضحى', 'آض', 'أمسى', 'انقلب', 'بات', 'تبدّل', 'تحوّل', 'حار', 'رجع', 'راح', 'صار', 'ظلّ', 'عاد', 'غدا', 'كان', 'ما انفك', 'ما برح', 'مادام', 'مازال', 'مافتئ', 'ابتدأ', 'أخذ', 'اخلولق', 'أقبل', 'انبرى', 'أنشأ', 'أوشك', 'جعل', 'حرى', 'شرع', 'طفق', 'علق', 'قام', 'كرب', 'كاد', 'هبّ']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw_nltk = stopwords.words('arabic')\n",
    "print(sw_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "af6a54ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_nltk = stopwords.words('arabic')\n",
    "df[\"line_of_poetry_split_stop\"]=df[\"line_of_poetry_split\"].apply(lambda x :[item for item in x if item not in sw_nltk ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "da9ffc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [خليلي, تستعجلا, ان, تزودا, وان, تجمعا, شملي, ...\n",
       "1          [فما, لبث, يوما, بسابق, مغنم, سرعتي, يوما, بسا...\n",
       "2          [وان, تنظراني, اليوم, اقض, لبانه, وتستوجبا, من...\n",
       "3                 [لعمرك, بجد, رشيده, تءامرني, لاصرم, مرثدا]\n",
       "4          [وان, ظهرت, قوارص, جمه, وافرع, لومي, مرارا, وا...\n",
       "                                 ...                        \n",
       "1831765      [اغلي, انشا, الله, الدنيا, واحلي, قصيده, تتغني]\n",
       "1831766    [اغروده, الاغاريد, تنساب, كحلم, يغشي, الجفون, ...\n",
       "1831767       [شلال, بهجه, وبهاء, يتداعي, وجدا, ويخفق, حسنا]\n",
       "1831768    [حلم, الهوي, ومنطلقي, الباقي, يدك, الحدود, سجن...\n",
       "1831769    [حبي, العاتي, وكل, غرامي, اه, ادرك, الغرام, لجنا]\n",
       "Name: line_of_poetry_split_stop, Length: 1831770, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"line_of_poetry_split_stop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "845847da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= df[\"line_of_poetry_split_stop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3a0d993c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>era</th>\n",
       "      <th>poet</th>\n",
       "      <th>poetical_works</th>\n",
       "      <th>rhyme</th>\n",
       "      <th>measure</th>\n",
       "      <th>r_hemistich</th>\n",
       "      <th>l_hemistich</th>\n",
       "      <th>line_of_poetry</th>\n",
       "      <th>line_of_poetry_split</th>\n",
       "      <th>line_of_poetry_split_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1831765</th>\n",
       "      <td>الحديث</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>ن</td>\n",
       "      <td>الخفيف</td>\n",
       "      <td>وأحلى قصيدة تتغنى</td>\n",
       "      <td>هي أغلى ما أنشأ الله في الدنيا</td>\n",
       "      <td>اغلي انشا الله الدنيا واحلي قصيده تتغني</td>\n",
       "      <td>[اغلي, انشا, الله, الدنيا, واحلي, قصيده, تتغني]</td>\n",
       "      <td>[اغلي, انشا, الله, الدنيا, واحلي, قصيده, تتغني]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831766</th>\n",
       "      <td>الحديث</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>ن</td>\n",
       "      <td>الخفيف</td>\n",
       "      <td>كحلم يغشى الجفون الوسنى</td>\n",
       "      <td>هي أغرودة الأغاريد تنساب</td>\n",
       "      <td>اغروده الاغاريد تنساب كحلم يغشي الجفون الوسني</td>\n",
       "      <td>[اغروده, الاغاريد, تنساب, كحلم, يغشي, الجفون, ...</td>\n",
       "      <td>[اغروده, الاغاريد, تنساب, كحلم, يغشي, الجفون, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831767</th>\n",
       "      <td>الحديث</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>ن</td>\n",
       "      <td>الخفيف</td>\n",
       "      <td>يتداعى وجدا ويخفق حسنا</td>\n",
       "      <td>هي شلال بهجة وبهاء</td>\n",
       "      <td>شلال بهجه وبهاء يتداعي وجدا ويخفق حسنا</td>\n",
       "      <td>[شلال, بهجه, وبهاء, يتداعي, وجدا, ويخفق, حسنا]</td>\n",
       "      <td>[شلال, بهجه, وبهاء, يتداعي, وجدا, ويخفق, حسنا]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831768</th>\n",
       "      <td>الحديث</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>ن</td>\n",
       "      <td>الخفيف</td>\n",
       "      <td>يدك الحدود سجنا فسجنا</td>\n",
       "      <td>هي حلم الهوى ومنطلقي الباقي</td>\n",
       "      <td>حلم الهوي ومنطلقي الباقي يدك الحدود سجنا فسجنا</td>\n",
       "      <td>[حلم, الهوي, ومنطلقي, الباقي, يدك, الحدود, سجن...</td>\n",
       "      <td>[حلم, الهوي, ومنطلقي, الباقي, يدك, الحدود, سجن...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831769</th>\n",
       "      <td>الحديث</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>ن</td>\n",
       "      <td>الخفيف</td>\n",
       "      <td>آه لو أدرك الغرام لجنا</td>\n",
       "      <td>هي حبي العاتي وكل غرامي</td>\n",
       "      <td>حبي العاتي وكل غرامي اه ادرك الغرام لجنا</td>\n",
       "      <td>[حبي, العاتي, وكل, غرامي, اه, ادرك, الغرام, لجنا]</td>\n",
       "      <td>[حبي, العاتي, وكل, غرامي, اه, ادرك, الغرام, لجنا]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            era       poet poetical_works rhyme measure  \\\n",
       "1831765  الحديث  شهاب غانم      شهاب غانم     ن  الخفيف   \n",
       "1831766  الحديث  شهاب غانم      شهاب غانم     ن  الخفيف   \n",
       "1831767  الحديث  شهاب غانم      شهاب غانم     ن  الخفيف   \n",
       "1831768  الحديث  شهاب غانم      شهاب غانم     ن  الخفيف   \n",
       "1831769  الحديث  شهاب غانم      شهاب غانم     ن  الخفيف   \n",
       "\n",
       "                     r_hemistich                     l_hemistich  \\\n",
       "1831765        وأحلى قصيدة تتغنى  هي أغلى ما أنشأ الله في الدنيا   \n",
       "1831766  كحلم يغشى الجفون الوسنى        هي أغرودة الأغاريد تنساب   \n",
       "1831767   يتداعى وجدا ويخفق حسنا              هي شلال بهجة وبهاء   \n",
       "1831768    يدك الحدود سجنا فسجنا     هي حلم الهوى ومنطلقي الباقي   \n",
       "1831769   آه لو أدرك الغرام لجنا         هي حبي العاتي وكل غرامي   \n",
       "\n",
       "                                         line_of_poetry  \\\n",
       "1831765         اغلي انشا الله الدنيا واحلي قصيده تتغني   \n",
       "1831766   اغروده الاغاريد تنساب كحلم يغشي الجفون الوسني   \n",
       "1831767          شلال بهجه وبهاء يتداعي وجدا ويخفق حسنا   \n",
       "1831768  حلم الهوي ومنطلقي الباقي يدك الحدود سجنا فسجنا   \n",
       "1831769        حبي العاتي وكل غرامي اه ادرك الغرام لجنا   \n",
       "\n",
       "                                      line_of_poetry_split  \\\n",
       "1831765    [اغلي, انشا, الله, الدنيا, واحلي, قصيده, تتغني]   \n",
       "1831766  [اغروده, الاغاريد, تنساب, كحلم, يغشي, الجفون, ...   \n",
       "1831767     [شلال, بهجه, وبهاء, يتداعي, وجدا, ويخفق, حسنا]   \n",
       "1831768  [حلم, الهوي, ومنطلقي, الباقي, يدك, الحدود, سجن...   \n",
       "1831769  [حبي, العاتي, وكل, غرامي, اه, ادرك, الغرام, لجنا]   \n",
       "\n",
       "                                 line_of_poetry_split_stop  \n",
       "1831765    [اغلي, انشا, الله, الدنيا, واحلي, قصيده, تتغني]  \n",
       "1831766  [اغروده, الاغاريد, تنساب, كحلم, يغشي, الجفون, ...  \n",
       "1831767     [شلال, بهجه, وبهاء, يتداعي, وجدا, ويخفق, حسنا]  \n",
       "1831768  [حلم, الهوي, ومنطلقي, الباقي, يدك, الحدود, سجن...  \n",
       "1831769  [حبي, العاتي, وكل, غرامي, اه, ادرك, الغرام, لجنا]  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "811fa935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.isri import ISRIStemmer\n",
    "st = ISRIStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d980ffae",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not DataFrame",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-f0ca62821479>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mdata_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m             raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n\u001b[0m\u001b[0;32m    342\u001b[0m                             f'not {s.__class__.__name__}')\n\u001b[0;32m    343\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetect_encoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'surrogatepass'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not DataFrame"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import http.client\n",
    "\n",
    "#####################\n",
    "text = df[\"line_of_poetry_split_stop\"]\n",
    "#####################\n",
    "\n",
    "text = text.replace('\"', '')\n",
    "conn = http.client.HTTPSConnection(\"farasa-api.qcri.org\")\n",
    "payload = \"{\\\"text\\\":\\\"%s\\\"}\"% text\n",
    "payload = payload.encode('utf-8')\n",
    "\n",
    "headers = { 'content-type': \"application/json\", 'cache-control': \"no-cache\", }\n",
    "\n",
    "conn.request(\"POST\", \"/msa/webapi/lemma\", payload, headers)\n",
    "\n",
    "res = conn.getresponse()\n",
    "\n",
    "data = res.read().decode('utf-8')\n",
    "data_dict = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "60095367",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-4d29a866de5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"line_of_poetry_split_ISRIStemmer\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"line_of_poetry_split\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "df[\"line_of_poetry_split_ISRIStemmer\"] = df[\"line_of_poetry_split\"].apply(st.stem.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "da8137e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-d390d85d4c58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mISRIStemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"line_of_poetry_split_stop\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mjoin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Windows-1256'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5463\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5464\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5465\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5467\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "from nltk.stem.isri import ISRIStemmer\n",
    "st = ISRIStemmer()\n",
    "w= df[\"line_of_poetry_split_stop\"]\n",
    "join = w.decode('Windows-1256')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d7467775",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-4de1a868888b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Call the function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-99-4de1a868888b>\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(word_list)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mwordsfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mstem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mwordsfilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \"\"\"\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m     return [\n\u001b[0;32m    132\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \"\"\"\n\u001b[0;32m    107\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tokenizers/punkt/{0}.pickle\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1272\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1273\u001b[0m         \"\"\"\n\u001b[1;32m-> 1274\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1326\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m         \"\"\"\n\u001b[1;32m-> 1328\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1326\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m         \"\"\"\n\u001b[1;32m-> 1328\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1316\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m             \u001b[0mslices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1318\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1319\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[1;34m(self, text, slices)\u001b[0m\n\u001b[0;32m   1357\u001b[0m         \"\"\"\n\u001b[0;32m   1358\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0msl1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1360\u001b[0m             \u001b[0msl1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msl2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[1;34m(it)\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[0mit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m         \u001b[0mprev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1330\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1332\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1333\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"after_tok\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "\n",
    "st = ISRIStemmer()\n",
    "word_list = df[\"line_of_poetry_split_stop\"]\n",
    "# Define a function\n",
    "def filter(word_list):\n",
    "    wordsfilter=[]\n",
    "    for a in word_tokenize(word_list):\n",
    "        stem = st.stem(a)\n",
    "        wordsfilter.append(stem)\n",
    "    print(wordsfilter)\n",
    "\n",
    "# Call the function\n",
    "filter(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eea24db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
